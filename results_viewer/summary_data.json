{
  "generated_at": "2026-01-21T21:13:24.571487",
  "experiment": {
    "started_at": "2026-01-20T17:08:09.555425",
    "vllm_version": "0.13.0",
    "datasets": [
      "mmlu",
      "mmlu_pro",
      "math_500",
      "gsm8k",
      "gpqa_diamond"
    ],
    "total_models": 1209
  },
  "status_counts": {
    "skipped": 822,
    "vllm_crash": 76,
    "test_error": 166,
    "success": 145
  },
  "failure_analysis": {
    "total_failures": 242,
    "by_category": {
      "missing_weights": 1,
      "oom_needs_more_tp": 2,
      "lora_adapter": 1,
      "eval_error": 59,
      "unknown": 60,
      "api_error": 100,
      "unsupported_quantization": 6,
      "oom_needs_more_gpu_mem": 7,
      "cuda_error": 2,
      "multimodal_not_supported": 3,
      "context_length_too_long": 1
    },
    "by_fixability": {
      "skip": 1,
      "easy_fix": 10,
      "not_fixable": 10,
      "needs_review": 221
    }
  },
  "actionable": {
    "retry": [
      "google/gemma-3-270m-it",
      "HuggingFaceTB/SmolLM2-135M-Instruct",
      "unsloth/gemma-3-270m-it",
      "LiquidAI/LFM2-350M-PII-Extract-JP",
      "LiquidAI/LFM2-350M-Extract",
      "LiquidAI/LFM2-350M",
      "ibm-granite/granite-4.0-350m",
      "LiquidAI/LFM2-350M-ENJP-MT",
      "HuggingFaceTB/SmolLM2-360M-Instruct",
      "LiquidAI/LFM2-350M-Math",
      "Ihor/Text2Graph-R1-Qwen2.5-0.5b",
      "KingNish/Reasoning-0.5b",
      "Gensyn/Qwen2.5-0.5B-Instruct",
      "openbmb/MiniCPM4-0.5B",
      "openbmb/BitCPM4-0.5B",
      "DeepMount00/Alireo-400m-instruct-v0.1",
      "PleIAs/Baguettotron",
      "ibm-granite/granite-4.0-h-350m",
      "jinaai/reader-lm-0.5b",
      "tiiuae/Falcon-H1-0.5B-Instruct",
      "LiquidAI/LFM2-700M",
      "tencent/Hunyuan-0.5B-Instruct",
      "quotientai/limbic-tool-use-0.5B-32K",
      "kz919/QwQ-0.5B-Distilled-SFT",
      "Qwen/Qwen3Guard-Gen-0.6B",
      "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B",
      "Qwen/Qwen3-0.6B-FP8",
      "Qwen/Qwen3-0.6B-Base",
      "baidu/ERNIE-4.5-0.3B-Base-PT",
      "Zyphra/Zamba2-1.2B-instruct",
      "unsloth/gemma-3-1b-it",
      "LiquidAI/LFM2-1.2B",
      "LiquidAI/LFM2-1.2B-Extract",
      "LiquidAI/LFM2-1.2B-RAG",
      "LiquidAI/LFM2-1.2B-Tool",
      "yasserrmd/DentaInstruct-1.2B",
      "ngxson/MiniThinky-v2-1B-Llama-3.2",
      "ibm-granite/granite-4.0-h-1b",
      "allenai/OLMo-2-0425-1B-Instruct",
      "ibm-granite/granite-3.1-1b-a400m-instruct",
      "Vikhrmodels/QVikhr-2.5-1.5B-Instruct-r",
      "DeepMount00/Qwen2-1.5B-Ita",
      "openbmb/BitCPM4-1B",
      "prem-research/prem-1B-SQL",
      "jinaai/ReaderLM-v2",
      "TIGER-Lab/general-verifier",
      "katanemo/Arch-Router-1.5B",
      "nvidia/OpenReasoning-Nemotron-1.5B",
      "nvidia/OpenMath-Nemotron-1.5B",
      "tiiuae/Falcon-H1-1.5B-Deep-Instruct",
      "ibm-granite/granite-4.0-1b",
      "dleemiller/Penny-1.7B",
      "WeiboAI/VibeThinker-1.5B",
      "Menlo/AlphaMaze-v0.2-1.5B",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "agentica-org/DeepScaleR-1.5B-Preview",
      "tencent/Hunyuan-1.8B-Instruct",
      "internlm/internlm2-chat-1_8b",
      "kakaocorp/kanana-nano-2.1b-instruct",
      "ByteDance/Ouro-1.4B",
      "HuggingFaceTB/SmolLM3-3B",
      "jet-ai/Jet-Nemotron-4B",
      "FractalAIResearch/Fathom-Synthesizer-4B",
      "Pinkstack/DistilGPT-OSS-qwen3-4B",
      "Qwen/Qwen3-4B-AWQ",
      "Intelligent-Internet/II-Search-4B",
      "allenai/OLMoE-1B-7B-0125-Instruct",
      "ByteDance/Ouro-2.6B-Thinking",
      "Qwen/Qwen3-4B-Instruct-2507-FP8",
      "ibm-granite/granite-4.0-h-micro",
      "nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
      "ByteDance/Ouro-2.6B",
      "ibm-granite/granite-4.0-tiny-preview",
      "AmanPriyanshu/gpt-oss-6.0b-specialized-all-pruned-moe-only-7-experts",
      "ibm-granite/granite-4.0-h-tiny",
      "Salesforce/xLAM-7b-r",
      "mistralai/Mistral-7B-Instruct-v0.2",
      "Navid-AI/Yehia-7B-preview",
      "humain-ai/ALLaM-7B-Instruct-preview",
      "aws-prototyping/MegaBeam-Mistral-7B-512k",
      "GritLM/GritLM-7B",
      "dmis-lab/meerkat-7b-v1.0",
      "moonshotai/Moonlight-16B-A3B",
      "norallm/normistral-7b-warm-instruct",
      "KurmaAI/AQUA-7B",
      "skt/A.X-4.0-Light",
      "skt/A.X-3.1-Light",
      "tiiuae/Falcon3-Mamba-7B-Instruct",
      "allenai/OLMo-2-1124-7B-Instruct",
      "inclusionAI/Ling-mini-2.0",
      "openbmb/MiniCPM3-4B",
      "ByteDance-Seed/BFS-Prover-V1-7B",
      "MiniMaxAI/SynLogic-7B",
      "IIC/RigoChat-7b-v2",
      "inclusionAI/Ling-lite",
      "inclusionAI/Ling-lite-1.5",
      "PhysicsWallahAI/Aryabhata-1.0",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "inclusionAI/Ling-lite-1.5-2507",
      "internlm/internlm2_5-7b-chat"
    ],
    "increase_tp": [
      "dousery/medical-reasoning-gpt-oss-20b",
      "Felladrin/Minueza-32M-Base",
      "nvidia/Hymba-1.5B-Base",
      "nvidia/Hymba-1.5B-Instruct",
      "kakaocorp/kanana-nano-2.1b-embedding",
      "lmms-lab/Aero-1-Audio",
      "Dream-org/Dream-Coder-v0-Instruct-7B",
      "Dream-org/Dream-v0-Base-7B",
      "Dream-org/Dream-v0-Instruct-7B"
    ],
    "skip": [
      "Rijgersberg/GEITje-7B-chat-v2"
    ],
    "not_fixable": [
      "ibm-granite/granite-guardian-3.2-5b-lora-harm-correction",
      "unsloth/Llama-3.2-1B-Instruct-bnb-4bit",
      "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit",
      "naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B",
      "erax-ai/EraX-Translator-V1.0",
      "neo4j/text-to-cypher-Gemma-3-4B-Instruct-2025.04.0",
      "unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit",
      "unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit",
      "secemp9/TraceBack-12b",
      "unsloth/Qwen2.5-7B-Instruct-bnb-4bit"
    ]
  },
  "failure_details": {
    "Rijgersberg/GEITje-7B-chat-v2": {
      "model_id": "Rijgersberg/GEITje-7B-chat-v2",
      "status": "vllm_crash",
      "category": "missing_weights",
      "fixability": "skip",
      "root_cause": "Model weights files are missing from the directory",
      "suggested_fix": "Re-download the model with all weight files",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2179569)\u001b[0;0m RuntimeError: Cannot find any model weights with `/mnt/baai_cp_perf/hf_models/models--Rijgersberg--GEITje-7B-chat-v2/snapshots/a5129be22534225cfee627837a7bafe100edcdb2`",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Rijgersberg__GEITje-7B-chat-v2_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.961440",
      "llm_used": false
    },
    "dousery/medical-reasoning-gpt-oss-20b": {
      "model_id": "dousery/medical-reasoning-gpt-oss-20b",
      "status": "vllm_crash",
      "category": "oom_needs_more_tp",
      "fixability": "easy_fix",
      "root_cause": "GPU out of memory - model too large for allocated GPUs",
      "suggested_fix": "Increase tensor_parallel_size in model config",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2146854)\u001b[0;0m torch.OutOfMemoryError: CUDA out of memory",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/dousery__medical-reasoning-gpt-oss-20b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.970540",
      "llm_used": false
    },
    "ibm-granite/granite-guardian-3.2-5b-lora-harm-correction": {
      "model_id": "ibm-granite/granite-guardian-3.2-5b-lora-harm-correction",
      "status": "vllm_crash",
      "category": "lora_adapter",
      "fixability": "not_fixable",
      "root_cause": "Model is a LoRA adapter, not a standalone model",
      "suggested_fix": "Need to load base model first, then apply LoRA adapter",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2146729)\u001b[0;0m ValueError: There is no module or parameter named 'base_model'",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-guardian-3.2-5b-lora-harm-correction_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.976692",
      "llm_used": false
    },
    "Felladrin/Minueza-32M-Base": {
      "model_id": "Felladrin/Minueza-32M-Base",
      "status": "test_error",
      "category": "oom_needs_more_tp",
      "fixability": "easy_fix",
      "root_cause": "GPU out of memory - model too large for allocated GPUs",
      "suggested_fix": "Increase tensor_parallel_size in model config",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2179581)\u001b[0;0m torch.OutOfMemoryError: CUDA out of memory",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Felladrin__Minueza-32M-Base_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.983489",
      "llm_used": false
    },
    "PleIAs/Monad": {
      "model_id": "PleIAs/Monad",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/PleIAs__Monad_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.990092",
      "llm_used": false
    },
    "Nikity/lille-130m-instruct": {
      "model_id": "Nikity/lille-130m-instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Nikity__lille-130m-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.994535",
      "llm_used": false
    },
    "google/gemma-3-270m-it": {
      "model_id": "google/gemma-3-270m-it",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--google--gemma-3-270m-it/snapshots/ac82b4e820549b854eebf28ce6dedaf9fdfa17b3` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/google__gemma-3-270m-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:09.998561",
      "llm_used": false
    },
    "HuggingFaceTB/SmolLM2-135M-Instruct": {
      "model_id": "HuggingFaceTB/SmolLM2-135M-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/12fd25f77366fa6b3b4b768ec3050bf629380bac` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/HuggingFaceTB__SmolLM2-135M-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.002873",
      "llm_used": false
    },
    "Felladrin/TinyMistral-248M-Chat-v4": {
      "model_id": "Felladrin/TinyMistral-248M-Chat-v4",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Felladrin__TinyMistral-248M-Chat-v4_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.010062",
      "llm_used": false
    },
    "unsloth/gemma-3-270m-it": {
      "model_id": "unsloth/gemma-3-270m-it",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--unsloth--gemma-3-270m-it/snapshots/23cf460f6bb16954176b3ddcc8d4f250501458a9` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__gemma-3-270m-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.014283",
      "llm_used": false
    },
    "LiquidAI/LFM2-350M-PII-Extract-JP": {
      "model_id": "LiquidAI/LFM2-350M-PII-Extract-JP",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-350M-PII-Extract-JP/snapshots/ce51280fea1c9426c127bb54047de09ec28e4376` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-350M-PII-Extract-JP_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.018534",
      "llm_used": false
    },
    "LiquidAI/LFM2-350M-Extract": {
      "model_id": "LiquidAI/LFM2-350M-Extract",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-350M-Extract/snapshots/d7c90e1819d7df5415ab1b766f4a9e6d9ef01919` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-350M-Extract_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.022890",
      "llm_used": false
    },
    "LiquidAI/LFM2-350M": {
      "model_id": "LiquidAI/LFM2-350M",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-350M/snapshots/28a2c07ba67e1a153f151fd132636514d7f1752a` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-350M_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.027166",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-350m": {
      "model_id": "ibm-granite/granite-4.0-350m",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-350m/snapshots/bd8a1497065c0d6ba1ef19af6b0d2b14bacf71c2` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-350m_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.031641",
      "llm_used": false
    },
    "LiquidAI/LFM2-350M-ENJP-MT": {
      "model_id": "LiquidAI/LFM2-350M-ENJP-MT",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-350M-ENJP-MT/snapshots/02fcc56f146ca4320c4c2217085fcfb4ac7a7a09` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-350M-ENJP-MT_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.036166",
      "llm_used": false
    },
    "HuggingFaceTB/SmolLM2-360M-Instruct": {
      "model_id": "HuggingFaceTB/SmolLM2-360M-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/a10cc1512eabd3dde888204e902eca88bddb4951` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/HuggingFaceTB__SmolLM2-360M-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.040743",
      "llm_used": false
    },
    "LiquidAI/LFM2-350M-Math": {
      "model_id": "LiquidAI/LFM2-350M-Math",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-350M-Math/snapshots/c690cd3413a05178a2a84618ad2416cbf6953138` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-350M-Math_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.045109",
      "llm_used": false
    },
    "Ihor/Text2Graph-R1-Qwen2.5-0.5b": {
      "model_id": "Ihor/Text2Graph-R1-Qwen2.5-0.5b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Ihor--Text2Graph-R1-Qwen2.5-0.5b/snapshots/a1727ba4577443b01b63c276ef208f0893be38da` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Ihor__Text2Graph-R1-Qwen2.5-0.5b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.046435",
      "llm_used": false
    },
    "KingNish/Reasoning-0.5b": {
      "model_id": "KingNish/Reasoning-0.5b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--KingNish--Reasoning-0.5b/snapshots/ec3c31a7907fee84c792b95ab3de597ee1e6521d` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/KingNish__Reasoning-0.5b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.047818",
      "llm_used": false
    },
    "Gensyn/Qwen2.5-0.5B-Instruct": {
      "model_id": "Gensyn/Qwen2.5-0.5B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Gensyn--Qwen2.5-0.5B-Instruct/snapshots/317b7eb96312eda0c431d1dab1af958a308cb35e` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Gensyn__Qwen2.5-0.5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.048957",
      "llm_used": false
    },
    "openbmb/MiniCPM4-0.5B": {
      "model_id": "openbmb/MiniCPM4-0.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--openbmb--MiniCPM4-0.5B/snapshots/5253c7fcc5e29e1cf3eacb59a58adf1ba4df8630` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/openbmb__MiniCPM4-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.050329",
      "llm_used": false
    },
    "openbmb/BitCPM4-0.5B": {
      "model_id": "openbmb/BitCPM4-0.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--openbmb--BitCPM4-0.5B/snapshots/4d0e4a9e2257ceb39d99b85bb946083467e8476f` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/openbmb__BitCPM4-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.051490",
      "llm_used": false
    },
    "DeepMount00/Alireo-400m-instruct-v0.1": {
      "model_id": "DeepMount00/Alireo-400m-instruct-v0.1",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--DeepMount00--Alireo-400m-instruct-v0.1/snapshots/4457428d3201286a03112b51f6c04f85771dc1ef` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/DeepMount00__Alireo-400m-instruct-v0.1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.052952",
      "llm_used": false
    },
    "PleIAs/Baguettotron": {
      "model_id": "PleIAs/Baguettotron",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--PleIAs--Baguettotron/snapshots/88f73c15f72fcb8472484331c176905c507d724c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/PleIAs__Baguettotron_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.054218",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-h-350m": {
      "model_id": "ibm-granite/granite-4.0-h-350m",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-h-350m/snapshots/3b17b717b8f2f5d305b0a92c1491e239aeda19c8` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-h-350m_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.055895",
      "llm_used": false
    },
    "manycore-research/SpatialLM-Qwen-0.5B": {
      "model_id": "manycore-research/SpatialLM-Qwen-0.5B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/manycore-research__SpatialLM-Qwen-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.060073",
      "llm_used": false
    },
    "manycore-research/SpatialLM1.1-Qwen-0.5B": {
      "model_id": "manycore-research/SpatialLM1.1-Qwen-0.5B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/manycore-research__SpatialLM1.1-Qwen-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.061533",
      "llm_used": false
    },
    "mlx-community/Llama-3.2-3B-Instruct-4bit": {
      "model_id": "mlx-community/Llama-3.2-3B-Instruct-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mlx-community__Llama-3.2-3B-Instruct-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.069732",
      "llm_used": false
    },
    "Qwen/Qwen3-4B-MLX-4bit": {
      "model_id": "Qwen/Qwen3-4B-MLX-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-4B-MLX-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.078126",
      "llm_used": false
    },
    "google/t5gemma-b-b-prefixlm-it": {
      "model_id": "google/t5gemma-b-b-prefixlm-it",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/google__t5gemma-b-b-prefixlm-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.079502",
      "llm_used": false
    },
    "unsloth/Qwen3-0.6B-unsloth-bnb-4bit": {
      "model_id": "unsloth/Qwen3-0.6B-unsloth-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Qwen3-0.6B-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.080759",
      "llm_used": false
    },
    "apple/FastVLM-0.5B": {
      "model_id": "apple/FastVLM-0.5B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/apple__FastVLM-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.081981",
      "llm_used": false
    },
    "tiiuae/Falcon-E-3B-Instruct": {
      "model_id": "tiiuae/Falcon-E-3B-Instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon-E-3B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.083300",
      "llm_used": false
    },
    "jinaai/reader-lm-0.5b": {
      "model_id": "jinaai/reader-lm-0.5b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--jinaai--reader-lm-0.5b/snapshots/46cb69fff9d100f9c3c2a135d59f365fb99a0121` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/jinaai__reader-lm-0.5b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.088032",
      "llm_used": false
    },
    "tiiuae/Falcon-H1-0.5B-Instruct": {
      "model_id": "tiiuae/Falcon-H1-0.5B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--tiiuae--Falcon-H1-0.5B-Instruct/snapshots/8f2587ca06bff78d8fa1adfccbe8c24d5f86b368` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon-H1-0.5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.095315",
      "llm_used": false
    },
    "LiquidAI/LFM2-700M": {
      "model_id": "LiquidAI/LFM2-700M",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-700M/snapshots/0f3cc1cb20ccf2867e9e9053514d74f85ea17ea0` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-700M_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.099892",
      "llm_used": false
    },
    "tencent/Hunyuan-0.5B-Instruct": {
      "model_id": "tencent/Hunyuan-0.5B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--tencent--Hunyuan-0.5B-Instruct/snapshots/2359fb220c010e9d6d62c62d466f0eda179c2cf3` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tencent__Hunyuan-0.5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.104652",
      "llm_used": false
    },
    "quotientai/limbic-tool-use-0.5B-32K": {
      "model_id": "quotientai/limbic-tool-use-0.5B-32K",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--quotientai--limbic-tool-use-0.5B-32K/snapshots/a27c2487431facd0c81a1024247fcdb364336970` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/quotientai__limbic-tool-use-0.5B-32K_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.108814",
      "llm_used": false
    },
    "kz919/QwQ-0.5B-Distilled-SFT": {
      "model_id": "kz919/QwQ-0.5B-Distilled-SFT",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--kz919--QwQ-0.5B-Distilled-SFT/snapshots/b732fdd3ae4d4d0327b2040b143631342a747f8e` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/kz919__QwQ-0.5B-Distilled-SFT_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.113073",
      "llm_used": false
    },
    "Qwen/Qwen3Guard-Gen-0.6B": {
      "model_id": "Qwen/Qwen3Guard-Gen-0.6B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Qwen--Qwen3Guard-Gen-0.6B/snapshots/fada3b2f655b89601929198343c94cd2f64d93cc` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3Guard-Gen-0.6B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.117607",
      "llm_used": false
    },
    "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B": {
      "model_id": "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--naver-hyperclovax--HyperCLOVAX-SEED-Text-Instruct-0.5B/snapshots/3da5046fb0195d14f2497de198136987d35fd644` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/naver-hyperclovax__HyperCLOVAX-SEED-Text-Instruct-0.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.119421",
      "llm_used": false
    },
    "Qwen/Qwen3-0.6B-FP8": {
      "model_id": "Qwen/Qwen3-0.6B-FP8",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Qwen--Qwen3-0.6B-FP8/snapshots/e5be08033360965ceca7b0ffd72d521a51331ce0` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-0.6B-FP8_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.124045",
      "llm_used": false
    },
    "Qwen/Qwen3-0.6B-Base": {
      "model_id": "Qwen/Qwen3-0.6B-Base",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--Qwen--Qwen3-0.6B-Base/snapshots/da87bfb608c14b7cf20ba1ce41287e8de496c0cd` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-0.6B-Base_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.125876",
      "llm_used": false
    },
    "baidu/ERNIE-4.5-0.3B-Base-PT": {
      "model_id": "baidu/ERNIE-4.5-0.3B-Base-PT",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--baidu--ERNIE-4.5-0.3B-Base-PT/snapshots/2d64320bf1b5b97f19a7eccf221fedb57e7ec02a` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/baidu__ERNIE-4.5-0.3B-Base-PT_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.127335",
      "llm_used": false
    },
    "manycore-research/SpatialLM-Llama-1B": {
      "model_id": "manycore-research/SpatialLM-Llama-1B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/manycore-research__SpatialLM-Llama-1B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.128576",
      "llm_used": false
    },
    "unsloth/Llama-3.2-1B-Instruct-bnb-4bit": {
      "model_id": "unsloth/Llama-3.2-1B-Instruct-bnb-4bit",
      "status": "test_error",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "bnb",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Llama-3.2-1B-Instruct-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.130261",
      "llm_used": false
    },
    "Zyphra/Zamba2-1.2B-instruct": {
      "model_id": "Zyphra/Zamba2-1.2B-instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Zyphra--Zamba2-1.2B-instruct/snapshots/c06b789753995762b3c11b3eeb39e38634f897e9` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Zyphra__Zamba2-1.2B-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.131923",
      "llm_used": false
    },
    "unsloth/gemma-3-1b-it": {
      "model_id": "unsloth/gemma-3-1b-it",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--unsloth--gemma-3-1b-it/snapshots/5b11413a10db4e486ef16a20101fd028f8f2499c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__gemma-3-1b-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.137089",
      "llm_used": false
    },
    "LiquidAI/LFM2-1.2B": {
      "model_id": "LiquidAI/LFM2-1.2B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-1.2B/snapshots/c97ace0b31ef13f116c70bc537ee6a1a8c501bc8` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-1.2B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.141423",
      "llm_used": false
    },
    "LiquidAI/LFM2-1.2B-Extract": {
      "model_id": "LiquidAI/LFM2-1.2B-Extract",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-1.2B-Extract/snapshots/1ff3a10d7db876c5cae2146e551157954f3daa1c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-1.2B-Extract_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.146121",
      "llm_used": false
    },
    "LiquidAI/LFM2-1.2B-RAG": {
      "model_id": "LiquidAI/LFM2-1.2B-RAG",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-1.2B-RAG/snapshots/f990742f828efec94cd997ad873d881359638613` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-1.2B-RAG_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.150971",
      "llm_used": false
    },
    "LiquidAI/LFM2-1.2B-Tool": {
      "model_id": "LiquidAI/LFM2-1.2B-Tool",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--LiquidAI--LFM2-1.2B-Tool/snapshots/e9fa2567f8a598b00359b487fae71dcc9f4fedad` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LiquidAI__LFM2-1.2B-Tool_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.155726",
      "llm_used": false
    },
    "yasserrmd/DentaInstruct-1.2B": {
      "model_id": "yasserrmd/DentaInstruct-1.2B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--yasserrmd--DentaInstruct-1.2B/snapshots/8a7b38c1fa12ae8ac357213bc4fb33d7b0d72f52` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/yasserrmd__DentaInstruct-1.2B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.160258",
      "llm_used": false
    },
    "ngxson/MiniThinky-v2-1B-Llama-3.2": {
      "model_id": "ngxson/MiniThinky-v2-1B-Llama-3.2",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ngxson--MiniThinky-v2-1B-Llama-3.2/snapshots/6a53b31cb0ea592e65195de157bc2a59cd6c3dc9` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ngxson__MiniThinky-v2-1B-Llama-3.2_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.164929",
      "llm_used": false
    },
    "nvidia/Hymba-1.5B-Base": {
      "model_id": "nvidia/Hymba-1.5B-Base",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__Hymba-1.5B-Base_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.190187",
      "llm_used": false
    },
    "nvidia/Hymba-1.5B-Instruct": {
      "model_id": "nvidia/Hymba-1.5B-Instruct",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__Hymba-1.5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.215434",
      "llm_used": false
    },
    "amd/AMD-OLMo-1B-SFT-DPO": {
      "model_id": "amd/AMD-OLMo-1B-SFT-DPO",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/amd__AMD-OLMo-1B-SFT-DPO_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.223859",
      "llm_used": false
    },
    "google/gemma-3-1b-it": {
      "model_id": "google/gemma-3-1b-it",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/google__gemma-3-1b-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.229362",
      "llm_used": false
    },
    "unsloth/Llama-3.2-1B-Instruct": {
      "model_id": "unsloth/Llama-3.2-1B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Llama-3.2-1B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.235007",
      "llm_used": false
    },
    "KurmaAI/AQUA-1B": {
      "model_id": "KurmaAI/AQUA-1B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/KurmaAI__AQUA-1B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.240447",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-h-1b": {
      "model_id": "ibm-granite/granite-4.0-h-1b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-h-1b/snapshots/d18cca4c121edb87d022116d281ce212c9136f57` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-h-1b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.246719",
      "llm_used": false
    },
    "allenai/OLMo-2-0425-1B-Instruct": {
      "model_id": "allenai/OLMo-2-0425-1B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--allenai--OLMo-2-0425-1B-Instruct/snapshots/48d788eca847d4d7548f375ad03d3c9312f6139e` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/allenai__OLMo-2-0425-1B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.251628",
      "llm_used": false
    },
    "ibm-granite/granite-3.1-1b-a400m-instruct": {
      "model_id": "ibm-granite/granite-3.1-1b-a400m-instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-3.1-1b-a400m-instruct/snapshots/b0e4fd07be563ba8bb7689c47dc9bebdff5471ab` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-3.1-1b-a400m-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.253415",
      "llm_used": false
    },
    "Vikhrmodels/QVikhr-2.5-1.5B-Instruct-r": {
      "model_id": "Vikhrmodels/QVikhr-2.5-1.5B-Instruct-r",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Vikhrmodels--QVikhr-2.5-1.5B-Instruct-r/snapshots/75879cfb701a5c185c07724171a619932c5ee13f` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Vikhrmodels__QVikhr-2.5-1.5B-Instruct-r_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.258928",
      "llm_used": false
    },
    "DeepMount00/Qwen2-1.5B-Ita": {
      "model_id": "DeepMount00/Qwen2-1.5B-Ita",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--DeepMount00--Qwen2-1.5B-Ita/snapshots/681e6db531df0cc3d7806251659b973ed4ff8c8f` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/DeepMount00__Qwen2-1.5B-Ita_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.264301",
      "llm_used": false
    },
    "openbmb/BitCPM4-1B": {
      "model_id": "openbmb/BitCPM4-1B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--openbmb--BitCPM4-1B/snapshots/70d989c4972efa636e8a2211975515d188e000b0` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/openbmb__BitCPM4-1B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.269668",
      "llm_used": false
    },
    "prem-research/prem-1B-SQL": {
      "model_id": "prem-research/prem-1B-SQL",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--prem-research--prem-1B-SQL/snapshots/44dd7fcf9227af4efed936bf29323c61bf66aad1` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/prem-research__prem-1B-SQL_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.275105",
      "llm_used": false
    },
    "baidu/ERNIE-4.5-0.3B-PT": {
      "model_id": "baidu/ERNIE-4.5-0.3B-PT",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/baidu__ERNIE-4.5-0.3B-PT_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.280562",
      "llm_used": false
    },
    "Qwen/Qwen3-0.6B": {
      "model_id": "Qwen/Qwen3-0.6B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-0.6B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.286119",
      "llm_used": false
    },
    "jinaai/ReaderLM-v2": {
      "model_id": "jinaai/ReaderLM-v2",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--jinaai--ReaderLM-v2/snapshots/1d07078459ee1e880a22d67387b5e683d50a6e4b` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/jinaai__ReaderLM-v2_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.288013",
      "llm_used": false
    },
    "TIGER-Lab/general-verifier": {
      "model_id": "TIGER-Lab/general-verifier",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--TIGER-Lab--general-verifier/snapshots/dc59c0c82360170cab0be91c91ae545ff32ea896` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/TIGER-Lab__general-verifier_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.293007",
      "llm_used": false
    },
    "katanemo/Arch-Router-1.5B": {
      "model_id": "katanemo/Arch-Router-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--katanemo--Arch-Router-1.5B/snapshots/0490c1af10854396a13682fb97b59eb9de2cb445` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/katanemo__Arch-Router-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.298625",
      "llm_used": false
    },
    "nvidia/OpenReasoning-Nemotron-1.5B": {
      "model_id": "nvidia/OpenReasoning-Nemotron-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--nvidia--OpenReasoning-Nemotron-1.5B/snapshots/f7e9c457f57387ce4eefa856795a5afa0622ec56` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__OpenReasoning-Nemotron-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.304123",
      "llm_used": false
    },
    "nvidia/OpenMath-Nemotron-1.5B": {
      "model_id": "nvidia/OpenMath-Nemotron-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--nvidia--OpenMath-Nemotron-1.5B/snapshots/59280da0e5508b98f4ae90e8886442f28ed561cb` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__OpenMath-Nemotron-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.309744",
      "llm_used": false
    },
    "Kortix/FastApply-1.5B-v1.0": {
      "model_id": "Kortix/FastApply-1.5B-v1.0",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Kortix__FastApply-1.5B-v1.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.315421",
      "llm_used": false
    },
    "jinaai/reader-lm-1.5b": {
      "model_id": "jinaai/reader-lm-1.5b",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/jinaai__reader-lm-1.5b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.324280",
      "llm_used": false
    },
    "Qwen/Qwen2.5-Coder-1.5B-Instruct": {
      "model_id": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen2.5-Coder-1.5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.329861",
      "llm_used": false
    },
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct": {
      "model_id": "tiiuae/Falcon-H1-1.5B-Deep-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--tiiuae--Falcon-H1-1.5B-Deep-Instruct/snapshots/b6648636ddc906688974282de6e7a243395f5423` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon-H1-1.5B-Deep-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.331765",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-1b": {
      "model_id": "ibm-granite/granite-4.0-1b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-1b/snapshots/6a7381ba1f54d684ff508d991aeb7dc580157103` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-1b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.337341",
      "llm_used": false
    },
    "dleemiller/Penny-1.7B": {
      "model_id": "dleemiller/Penny-1.7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--dleemiller--Penny-1.7B/snapshots/451ad8e59107cb4afd399b7b69fd362fa667ff80` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/dleemiller__Penny-1.7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.342793",
      "llm_used": false
    },
    "tiiuae/Falcon3-1B-Instruct": {
      "model_id": "tiiuae/Falcon3-1B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon3-1B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.350959",
      "llm_used": false
    },
    "pints-ai/1.5-Pints-2K-v0.1": {
      "model_id": "pints-ai/1.5-Pints-2K-v0.1",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/pints-ai__1.5-Pints-2K-v0.1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.357266",
      "llm_used": false
    },
    "WeiboAI/VibeThinker-1.5B": {
      "model_id": "WeiboAI/VibeThinker-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--WeiboAI--VibeThinker-1.5B/snapshots/dbc405deea53a29597ac31a044943472af6f7e08` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/WeiboAI__VibeThinker-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.362726",
      "llm_used": false
    },
    "Menlo/AlphaMaze-v0.2-1.5B": {
      "model_id": "Menlo/AlphaMaze-v0.2-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Menlo--AlphaMaze-v0.2-1.5B/snapshots/2a7c08f3614fa672bb1be573b210b3b5e575cd30` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Menlo__AlphaMaze-v0.2-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.368310",
      "llm_used": false
    },
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
      "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/deepseek-ai__DeepSeek-R1-Distill-Qwen-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.373901",
      "llm_used": false
    },
    "agentica-org/DeepScaleR-1.5B-Preview": {
      "model_id": "agentica-org/DeepScaleR-1.5B-Preview",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--agentica-org--DeepScaleR-1.5B-Preview/snapshots/e3f524ce413a296b4d388e7560dd5c82c1c56725` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/agentica-org__DeepScaleR-1.5B-Preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.379686",
      "llm_used": false
    },
    "UnfilteredAI/DAN-Qwen3-1.7B": {
      "model_id": "UnfilteredAI/DAN-Qwen3-1.7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/UnfilteredAI__DAN-Qwen3-1.7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.385591",
      "llm_used": false
    },
    "janhq/Jan-v1-edge": {
      "model_id": "janhq/Jan-v1-edge",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/janhq__Jan-v1-edge_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.391311",
      "llm_used": false
    },
    "nvidia/AceInstruct-1.5B": {
      "model_id": "nvidia/AceInstruct-1.5B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__AceInstruct-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.400272",
      "llm_used": false
    },
    "knoveleng/Open-RS3": {
      "model_id": "knoveleng/Open-RS3",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/knoveleng__Open-RS3_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.409079",
      "llm_used": false
    },
    "tencent/Hunyuan-1.8B-Instruct": {
      "model_id": "tencent/Hunyuan-1.8B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--tencent--Hunyuan-1.8B-Instruct/snapshots/de940610ab5d45b4fedbd37e08444d0dc502837c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tencent__Hunyuan-1.8B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.411154",
      "llm_used": false
    },
    "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit": {
      "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit",
      "status": "test_error",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2454534)\u001b[0;0m   File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/vllm/model_executor/layers/quantization/bitsandbytes",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.416413",
      "llm_used": false
    },
    "apple/FastVLM-1.5B": {
      "model_id": "apple/FastVLM-1.5B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/apple__FastVLM-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.418131",
      "llm_used": false
    },
    "Salesforce/CoDA-v0-Instruct": {
      "model_id": "Salesforce/CoDA-v0-Instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Salesforce__CoDA-v0-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.420126",
      "llm_used": false
    },
    "internlm/internlm2-chat-1_8b": {
      "model_id": "internlm/internlm2-chat-1_8b",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--internlm--internlm2-chat-1_8b/snapshots/21ccc6447f57c3c6dd2a78e2248bd6afbe0133e1` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/internlm__internlm2-chat-1_8b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.425216",
      "llm_used": false
    },
    "kakaocorp/kanana-nano-2.1b-embedding": {
      "model_id": "kakaocorp/kanana-nano-2.1b-embedding",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/kakaocorp__kanana-nano-2.1b-embedding_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.450083",
      "llm_used": false
    },
    "kakaocorp/kanana-nano-2.1b-instruct": {
      "model_id": "kakaocorp/kanana-nano-2.1b-instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--kakaocorp--kanana-nano-2.1b-instruct/snapshots/e12a48d5386ceb7dd608533e8ffaea82d6070554` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/kakaocorp__kanana-nano-2.1b-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.456333",
      "llm_used": false
    },
    "LGAI-EXAONE/EXAONE-Deep-2.4B-AWQ": {
      "model_id": "LGAI-EXAONE/EXAONE-Deep-2.4B-AWQ",
      "status": "vllm_crash",
      "category": "cuda_error",
      "fixability": "needs_review",
      "root_cause": "CUDA runtime error",
      "suggested_fix": "Check GPU compatibility and driver version",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=2499302)\u001b[0;0m torch.AcceleratorError: CUDA error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/LGAI-EXAONE__EXAONE-Deep-2.4B-AWQ_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.476566",
      "llm_used": false
    },
    "lmms-lab/Aero-1-Audio": {
      "model_id": "lmms-lab/Aero-1-Audio",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/lmms-lab__Aero-1-Audio_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.502033",
      "llm_used": false
    },
    "jinaai/jina-reranker-m0": {
      "model_id": "jinaai/jina-reranker-m0",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/jinaai__jina-reranker-m0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.503941",
      "llm_used": false
    },
    "PerceptronAI/Isaac-0.1": {
      "model_id": "PerceptronAI/Isaac-0.1",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/PerceptronAI__Isaac-0.1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.505897",
      "llm_used": false
    },
    "Motif-Technologies/Motif-2.6B": {
      "model_id": "Motif-Technologies/Motif-2.6B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Motif-Technologies__Motif-2.6B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.507764",
      "llm_used": false
    },
    "Motif-Technologies/Motif-2.6b-v1.1-LC": {
      "model_id": "Motif-Technologies/Motif-2.6b-v1.1-LC",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Motif-Technologies__Motif-2.6b-v1.1-LC_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.509714",
      "llm_used": false
    },
    "MBZUAI-Paris/Atlas-Chat-2B": {
      "model_id": "MBZUAI-Paris/Atlas-Chat-2B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/MBZUAI-Paris__Atlas-Chat-2B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.511573",
      "llm_used": false
    },
    "Metin/Gemma-2-2B-TR-Knowledge-Graph": {
      "model_id": "Metin/Gemma-2-2B-TR-Knowledge-Graph",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Metin__Gemma-2-2B-TR-Knowledge-Graph_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.513316",
      "llm_used": false
    },
    "Unbabel/Tower-Plus-2B": {
      "model_id": "Unbabel/Tower-Plus-2B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Unbabel__Tower-Plus-2B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.528105",
      "llm_used": false
    },
    "rinna/gemma-2-baku-2b-it": {
      "model_id": "rinna/gemma-2-baku-2b-it",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/rinna__gemma-2-baku-2b-it_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.530173",
      "llm_used": false
    },
    "silma-ai/SILMA-Kashif-2B-Instruct-v1.0": {
      "model_id": "silma-ai/SILMA-Kashif-2B-Instruct-v1.0",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/silma-ai__SILMA-Kashif-2B-Instruct-v1.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.531889",
      "llm_used": false
    },
    "winninghealth/WiNGPT-Babel-2": {
      "model_id": "winninghealth/WiNGPT-Babel-2",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/winninghealth__WiNGPT-Babel-2_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.546712",
      "llm_used": false
    },
    "yanolja/YanoljaNEXT-EEVE-2.8B": {
      "model_id": "yanolja/YanoljaNEXT-EEVE-2.8B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/yanolja__YanoljaNEXT-EEVE-2.8B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.552883",
      "llm_used": false
    },
    "ragraph-ai/stable-cypher-instruct-3b": {
      "model_id": "ragraph-ai/stable-cypher-instruct-3b",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ragraph-ai__stable-cypher-instruct-3b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.554916",
      "llm_used": false
    },
    "ByteDance/Ouro-1.4B": {
      "model_id": "ByteDance/Ouro-1.4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ByteDance--Ouro-1.4B/snapshots/fcfcfbc429c7b10ee73dfc718033351d8936d2a8` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ByteDance__Ouro-1.4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.559330",
      "llm_used": false
    },
    "HuggingFaceTB/SmolLM3-3B": {
      "model_id": "HuggingFaceTB/SmolLM3-3B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--HuggingFaceTB--SmolLM3-3B/snapshots/a07cc9a04f16550a088caea529712d1d335b0ac1` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/HuggingFaceTB__SmolLM3-3B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.561433",
      "llm_used": false
    },
    "yanolja/YanoljaNEXT-EEVE-Instruct-2.8B": {
      "model_id": "yanolja/YanoljaNEXT-EEVE-Instruct-2.8B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/yanolja__YanoljaNEXT-EEVE-Instruct-2.8B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.571736",
      "llm_used": false
    },
    "Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B": {
      "model_id": "Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Skywork__Skywork-o1-Open-PRM-Qwen-2.5-1.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.573862",
      "llm_used": false
    },
    "amd/Instella-3B-Instruct": {
      "model_id": "amd/Instella-3B-Instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/amd__Instella-3B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.575860",
      "llm_used": false
    },
    "tiiuae/Falcon3-10B-Instruct-1.58bit": {
      "model_id": "tiiuae/Falcon3-10B-Instruct-1.58bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon3-10B-Instruct-1.58bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.577757",
      "llm_used": false
    },
    "ModelSpace/GemmaX2-28-2B-v0.1": {
      "model_id": "ModelSpace/GemmaX2-28-2B-v0.1",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ModelSpace__GemmaX2-28-2B-v0.1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.579746",
      "llm_used": false
    },
    "unsloth/Llama-3.2-3B-Instruct-bnb-4bit": {
      "model_id": "unsloth/Llama-3.2-3B-Instruct-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Llama-3.2-3B-Instruct-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.581876",
      "llm_used": false
    },
    "Writer/palmyra-mini": {
      "model_id": "Writer/palmyra-mini",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Writer__palmyra-mini_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.583818",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-micro": {
      "model_id": "ibm-granite/granite-4.0-micro",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-micro_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.589961",
      "llm_used": false
    },
    "Writer/palmyra-mini-thinking-a": {
      "model_id": "Writer/palmyra-mini-thinking-a",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Writer__palmyra-mini-thinking-a_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.595897",
      "llm_used": false
    },
    "naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B": {
      "model_id": "naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B",
      "status": "vllm_crash",
      "category": "multimodal_not_supported",
      "fixability": "not_fixable",
      "root_cause": "Multimodal model not supported for text-only evaluation",
      "suggested_fix": "Use multimodal evaluation pipeline",
      "error_snippet": "\u001b[0;36m(APIServer pid=2601856)\u001b[0;0m   Value error, Model architectures ['HCXVision",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/naver-hyperclovax__HyperCLOVAX-SEED-Vision-Instruct-3B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.601771",
      "llm_used": false
    },
    "SicariusSicariiStuff/Phi-3.5-mini-instruct_Uncensored": {
      "model_id": "SicariusSicariiStuff/Phi-3.5-mini-instruct_Uncensored",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/SicariusSicariiStuff__Phi-3.5-mini-instruct_Uncensored_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.603728",
      "llm_used": false
    },
    "moelanoby/phi-3-M3-coder": {
      "model_id": "moelanoby/phi-3-M3-coder",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/moelanoby__phi-3-M3-coder_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.605753",
      "llm_used": false
    },
    "microsoft/Phi-4-mini-instruct": {
      "model_id": "microsoft/Phi-4-mini-instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/microsoft__Phi-4-mini-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.611739",
      "llm_used": false
    },
    "microsoft/Phi-4-mini-flash-reasoning": {
      "model_id": "microsoft/Phi-4-mini-flash-reasoning",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/microsoft__Phi-4-mini-flash-reasoning_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.614008",
      "llm_used": false
    },
    "microsoft/Phi-4-mini-reasoning": {
      "model_id": "microsoft/Phi-4-mini-reasoning",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/microsoft__Phi-4-mini-reasoning_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.619996",
      "llm_used": false
    },
    "tomg-group-umd/huginn-0125": {
      "model_id": "tomg-group-umd/huginn-0125",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tomg-group-umd__huginn-0125_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.642724",
      "llm_used": false
    },
    "unsloth/Phi-4-mini-instruct-unsloth-bnb-4bit": {
      "model_id": "unsloth/Phi-4-mini-instruct-unsloth-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Phi-4-mini-instruct-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.644948",
      "llm_used": false
    },
    "jet-ai/Jet-Nemotron-4B": {
      "model_id": "jet-ai/Jet-Nemotron-4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--jet-ai--Jet-Nemotron-4B/snapshots/950eaee5ae588210ed2e49d9bc623231aa27fdea` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/jet-ai__Jet-Nemotron-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.647269",
      "llm_used": false
    },
    "MBZUAI-Paris/Nile-Chat-4B": {
      "model_id": "MBZUAI-Paris/Nile-Chat-4B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/MBZUAI-Paris__Nile-Chat-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.674846",
      "llm_used": false
    },
    "yanolja/YanoljaNEXT-Rosetta-4B": {
      "model_id": "yanolja/YanoljaNEXT-Rosetta-4B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/yanolja__YanoljaNEXT-Rosetta-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.681427",
      "llm_used": false
    },
    "FractalAIResearch/Fathom-Synthesizer-4B": {
      "model_id": "FractalAIResearch/Fathom-Synthesizer-4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--FractalAIResearch--Fathom-Synthesizer-4B/snapshots/fa37e5602641e5009b80bb51c2197a8069aa18de` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/FractalAIResearch__Fathom-Synthesizer-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.684006",
      "llm_used": false
    },
    "Pinkstack/DistilGPT-OSS-qwen3-4B": {
      "model_id": "Pinkstack/DistilGPT-OSS-qwen3-4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Pinkstack--DistilGPT-OSS-qwen3-4B/snapshots/1e918870ecf8387bcff3b8e7091363d3e7285b22` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Pinkstack__DistilGPT-OSS-qwen3-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.686265",
      "llm_used": false
    },
    "Qwen/Qwen3-4B-AWQ": {
      "model_id": "Qwen/Qwen3-4B-AWQ",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Qwen--Qwen3-4B-AWQ/snapshots/74d4bd2bd4bff9cafc9345221320bffb08b406a3` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-4B-AWQ_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.688574",
      "llm_used": false
    },
    "driaforall/mem-agent": {
      "model_id": "driaforall/mem-agent",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/driaforall__mem-agent_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.718739",
      "llm_used": false
    },
    "erax-ai/EraX-Translator-V1.0": {
      "model_id": "erax-ai/EraX-Translator-V1.0",
      "status": "test_error",
      "category": "multimodal_not_supported",
      "fixability": "not_fixable",
      "root_cause": "Multimodal model not supported for text-only evaluation",
      "suggested_fix": "Use multimodal evaluation pipeline",
      "error_snippet": "image",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/erax-ai__EraX-Translator-V1.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.723383",
      "llm_used": false
    },
    "neo4j/text-to-cypher-Gemma-3-4B-Instruct-2025.04.0": {
      "model_id": "neo4j/text-to-cypher-Gemma-3-4B-Instruct-2025.04.0",
      "status": "test_error",
      "category": "multimodal_not_supported",
      "fixability": "not_fixable",
      "root_cause": "Multimodal model not supported for text-only evaluation",
      "suggested_fix": "Use multimodal evaluation pipeline",
      "error_snippet": "image",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/neo4j__text-to-cypher-Gemma-3-4B-Instruct-2025.04.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.727628",
      "llm_used": false
    },
    "soob3123/amoral-gemma3-4B-v1": {
      "model_id": "soob3123/amoral-gemma3-4B-v1",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/soob3123__amoral-gemma3-4B-v1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.736337",
      "llm_used": false
    },
    "Intelligent-Internet/II-Search-4B": {
      "model_id": "Intelligent-Internet/II-Search-4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Intelligent-Internet--II-Search-4B/snapshots/d54fe4d3321120859f68e38ea9169e704778e5d7` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Intelligent-Internet__II-Search-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.743290",
      "llm_used": false
    },
    "ServiceNow-AI/Apriel-5B-Instruct": {
      "model_id": "ServiceNow-AI/Apriel-5B-Instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ServiceNow-AI__Apriel-5B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.745625",
      "llm_used": false
    },
    "lmstudio-community/Qwen3-30B-A3B-MLX-4bit": {
      "model_id": "lmstudio-community/Qwen3-30B-A3B-MLX-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/lmstudio-community__Qwen3-30B-A3B-MLX-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.747864",
      "llm_used": false
    },
    "unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit": {
      "model_id": "unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.750053",
      "llm_used": false
    },
    "mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit": {
      "model_id": "mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mlx-community__DeepSeek-R1-Distill-Qwen-32B-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.774626",
      "llm_used": false
    },
    "unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit": {
      "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit",
      "status": "vllm_crash",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=759460)\u001b[0;0m   File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/vllm/model_executor/layers/quantization/bitsandbytes",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.780344",
      "llm_used": false
    },
    "cpatonn/Qwen3-Coder-30B-A3B-Instruct-AWQ-4bit": {
      "model_id": "cpatonn/Qwen3-Coder-30B-A3B-Instruct-AWQ-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/cpatonn__Qwen3-Coder-30B-A3B-Instruct-AWQ-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.802679",
      "llm_used": false
    },
    "cpatonn/Qwen3-30B-A3B-Instruct-2507-AWQ-4bit": {
      "model_id": "cpatonn/Qwen3-30B-A3B-Instruct-2507-AWQ-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/cpatonn__Qwen3-30B-A3B-Instruct-2507-AWQ-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.804867",
      "llm_used": false
    },
    "unsloth/phi-4-unsloth-bnb-4bit": {
      "model_id": "unsloth/phi-4-unsloth-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__phi-4-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.806965",
      "llm_used": false
    },
    "allenai/OLMoE-1B-7B-0125-Instruct": {
      "model_id": "allenai/OLMoE-1B-7B-0125-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--allenai--OLMoE-1B-7B-0125-Instruct/snapshots/b89a7c4bc24fb9e55ce2543c9458ce0ca5c4650e` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/allenai__OLMoE-1B-7B-0125-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.812857",
      "llm_used": false
    },
    "ByteDance/Ouro-2.6B-Thinking": {
      "model_id": "ByteDance/Ouro-2.6B-Thinking",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ByteDance--Ouro-2.6B-Thinking/snapshots/dafed72e123c3a1fb0ca03bfeab492cc8ad3a003` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ByteDance__Ouro-2.6B-Thinking_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.843770",
      "llm_used": false
    },
    "arcee-ai/AFM-4.5B": {
      "model_id": "arcee-ai/AFM-4.5B",
      "status": "test_error",
      "category": "context_length_too_long",
      "fixability": "easy_fix",
      "root_cause": "Input exceeds maximum context length",
      "suggested_fix": "Reduce max_model_len or input length",
      "error_snippet": "position_embeddings / config.rope_scaling['original_max_position_embeddings'] = 16.0). Using the explicit factor (20.0) in YaRN. This may cause unexpected behaviour in model usage, please correct the 'max_position_embeddings' fields in the model config.",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/arcee-ai__AFM-4.5B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.849274",
      "llm_used": false
    },
    "Qwen/Qwen3-4B-Instruct-2507-FP8": {
      "model_id": "Qwen/Qwen3-4B-Instruct-2507-FP8",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--Qwen--Qwen3-4B-Instruct-2507-FP8/snapshots/8591804019c8b22094c3b5b4454e0edc05dffc98` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen3-4B-Instruct-2507-FP8_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.856422",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-h-micro": {
      "model_id": "ibm-granite/granite-4.0-h-micro",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-h-micro/snapshots/d5f01a3ea75f088947be3aae039f4ad52837dfde` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-h-micro_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.863575",
      "llm_used": false
    },
    "nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1": {
      "model_id": "nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--nvidia--Llama-3.1-Nemotron-Nano-4B-v1.1/snapshots/d552708a9d575fa8d4a690b988fd870d65279f98` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__Llama-3.1-Nemotron-Nano-4B-v1.1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.870184",
      "llm_used": false
    },
    "ByteDance/Ouro-2.6B": {
      "model_id": "ByteDance/Ouro-2.6B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ByteDance--Ouro-2.6B/snapshots/514f6e4eeebd78600d4708993e8ea1021e038aec` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ByteDance__Ouro-2.6B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.878157",
      "llm_used": false
    },
    "unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit": {
      "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit",
      "status": "test_error",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "bnb",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.881063",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-tiny-preview": {
      "model_id": "ibm-granite/granite-4.0-tiny-preview",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ibm-granite--granite-4.0-tiny-preview/snapshots/4ec5f963443b2e15e9be82595289e96ff082e280` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-tiny-preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.907569",
      "llm_used": false
    },
    "AmanPriyanshu/gpt-oss-6.0b-specialized-all-pruned-moe-only-7-experts": {
      "model_id": "AmanPriyanshu/gpt-oss-6.0b-specialized-all-pruned-moe-only-7-experts",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--AmanPriyanshu--gpt-oss-6.0b-specialized-all-pruned-moe-only-7-experts/snapshots/a1599a4d8b40849c8dd0c676b681b90a05954091` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/AmanPriyanshu__gpt-oss-6.0b-specialized-all-pruned-moe-only-7-experts_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.910530",
      "llm_used": false
    },
    "secemp9/TraceBack-12b": {
      "model_id": "secemp9/TraceBack-12b",
      "status": "vllm_crash",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=765915)\u001b[0;0m   File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/vllm/model_executor/layers/quantization/bitsandbytes",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/secemp9__TraceBack-12b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.917285",
      "llm_used": false
    },
    "Salesforce/xLAM-7b-fc-r": {
      "model_id": "Salesforce/xLAM-7b-fc-r",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Salesforce__xLAM-7b-fc-r_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.923659",
      "llm_used": false
    },
    "ibm-granite/granite-4.0-h-tiny": {
      "model_id": "ibm-granite/granite-4.0-h-tiny",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--ibm-granite--granite-4.0-h-tiny/snapshots/791e0d3d28c86e106c9b6e0b4cecdee0375b6124` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ibm-granite__granite-4.0-h-tiny_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.952519",
      "llm_used": false
    },
    "Salesforce/xLAM-7b-r": {
      "model_id": "Salesforce/xLAM-7b-r",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--Salesforce--xLAM-7b-r/snapshots/c07be3dc558bdb1dcc51c1d06b030131c3d3dcea` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Salesforce__xLAM-7b-r_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.959779",
      "llm_used": false
    },
    "mistralai/Mistral-7B-Instruct-v0.2": {
      "model_id": "mistralai/Mistral-7B-Instruct-v0.2",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mistralai__Mistral-7B-Instruct-v0.2_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.967046",
      "llm_used": false
    },
    "Navid-AI/Yehia-7B-preview": {
      "model_id": "Navid-AI/Yehia-7B-preview",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--Navid-AI--Yehia-7B-preview/snapshots/441238d528c05538f0b5e1126873d7bef5ad7563` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Navid-AI__Yehia-7B-preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.974489",
      "llm_used": false
    },
    "humain-ai/ALLaM-7B-Instruct-preview": {
      "model_id": "humain-ai/ALLaM-7B-Instruct-preview",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--humain-ai--ALLaM-7B-Instruct-preview/snapshots/a28dd1e67420cde72d3629c8633a974cf7d9c366` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/humain-ai__ALLaM-7B-Instruct-preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.981863",
      "llm_used": false
    },
    "aws-prototyping/MegaBeam-Mistral-7B-512k": {
      "model_id": "aws-prototyping/MegaBeam-Mistral-7B-512k",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--aws-prototyping--MegaBeam-Mistral-7B-512k/snapshots/7a9bfb11b5d5e56eae0e4b52290d705cdd55f7a6` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/aws-prototyping__MegaBeam-Mistral-7B-512k_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.989760",
      "llm_used": false
    },
    "GritLM/GritLM-7B": {
      "model_id": "GritLM/GritLM-7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--GritLM--GritLM-7B/snapshots/138192cc56441e22a92f37ca05bdfff64ec3d83f` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/GritLM__GritLM-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:10.997167",
      "llm_used": false
    },
    "OpenLLM-France/Lucie-7B": {
      "model_id": "OpenLLM-France/Lucie-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/OpenLLM-France__Lucie-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.026806",
      "llm_used": false
    },
    "dmis-lab/meerkat-7b-v1.0": {
      "model_id": "dmis-lab/meerkat-7b-v1.0",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--dmis-lab--meerkat-7b-v1.0/snapshots/e3ea5ec3a4bb0b718e822878a8c01873b01d49a2` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/dmis-lab__meerkat-7b-v1.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.029649",
      "llm_used": false
    },
    "moonshotai/Moonlight-16B-A3B": {
      "model_id": "moonshotai/Moonlight-16B-A3B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--moonshotai--Moonlight-16B-A3B/snapshots/ce8bc137e6e29c3b7540ebdd515bbc5bdb20d915` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/moonshotai__Moonlight-16B-A3B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.032505",
      "llm_used": false
    },
    "inclusionAI/LLaDA-MoE-7B-A1B-Base": {
      "model_id": "inclusionAI/LLaDA-MoE-7B-A1B-Base",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__LLaDA-MoE-7B-A1B-Base_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.035013",
      "llm_used": false
    },
    "NousResearch/Genstruct-7B": {
      "model_id": "NousResearch/Genstruct-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 400 - {'error': {'message': \"'dict object' has no attribute 'title' 'dict object' has no attribute 'title'\", 'type': 'BadRequestError', 'param': None, 'code': 400}}",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/NousResearch__Genstruct-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.059086",
      "llm_used": false
    },
    "icefog72/IceMoonshineRP-7b": {
      "model_id": "icefog72/IceMoonshineRP-7b",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/icefog72__IceMoonshineRP-7b_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.065596",
      "llm_used": false
    },
    "kakaocorp/kanana-1.5-15.7b-a3b-instruct": {
      "model_id": "kakaocorp/kanana-1.5-15.7b-a3b-instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/kakaocorp__kanana-1.5-15.7b-a3b-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.072281",
      "llm_used": false
    },
    "microsoft/Phi-3-small-128k-instruct": {
      "model_id": "microsoft/Phi-3-small-128k-instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/microsoft__Phi-3-small-128k-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.080263",
      "llm_used": false
    },
    "microsoft/Phi-3-small-8k-instruct": {
      "model_id": "microsoft/Phi-3-small-8k-instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/microsoft__Phi-3-small-8k-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.082865",
      "llm_used": false
    },
    "inclusionAI/LLaDA2.0-mini-preview": {
      "model_id": "inclusionAI/LLaDA2.0-mini-preview",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__LLaDA2.0-mini-preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.085665",
      "llm_used": false
    },
    "norallm/normistral-7b-warm-instruct": {
      "model_id": "norallm/normistral-7b-warm-instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--norallm--normistral-7b-warm-instruct/snapshots/85fba0b42363f6ebbb15e627cb31fc082b8ca226` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/norallm__normistral-7b-warm-instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.093131",
      "llm_used": false
    },
    "KurmaAI/AQUA-7B": {
      "model_id": "KurmaAI/AQUA-7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--KurmaAI--AQUA-7B/snapshots/412343ca3d4fcabb5de170211cc9dc856574365c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/KurmaAI__AQUA-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.100779",
      "llm_used": false
    },
    "skt/A.X-4.0-Light": {
      "model_id": "skt/A.X-4.0-Light",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--skt--A.X-4.0-Light/snapshots/ba21c20ea1b31ded1ec3e2fb432335077dc4be98` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/skt__A.X-4.0-Light_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.108127",
      "llm_used": false
    },
    "skt/A.X-3.1-Light": {
      "model_id": "skt/A.X-3.1-Light",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--skt--A.X-3.1-Light/snapshots/9b41bb2406472634d8812c0b8931fa40fa9a6c3a` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/skt__A.X-3.1-Light_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.115586",
      "llm_used": false
    },
    "tiiuae/Falcon3-Mamba-7B-Instruct": {
      "model_id": "tiiuae/Falcon3-Mamba-7B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--tiiuae--Falcon3-Mamba-7B-Instruct/snapshots/79268d5c8e650ec0ec24aad2729bfc906f569580` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon3-Mamba-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.125900",
      "llm_used": false
    },
    "allenai/OLMo-2-1124-7B-Instruct": {
      "model_id": "allenai/OLMo-2-1124-7B-Instruct",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--allenai--OLMo-2-1124-7B-Instruct/snapshots/470b1fba1ae01581f270116362ee4aa1b97f4c84` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/allenai__OLMo-2-1124-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.134439",
      "llm_used": false
    },
    "Infinigence/Megrez2-3x7B-A3B": {
      "model_id": "Infinigence/Megrez2-3x7B-A3B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Infinigence__Megrez2-3x7B-A3B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.137294",
      "llm_used": false
    },
    "Zyphra/Zamba2-7B-Instruct": {
      "model_id": "Zyphra/Zamba2-7B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Zyphra__Zamba2-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.143008",
      "llm_used": false
    },
    "internlm/internlm2-7b-reward": {
      "model_id": "internlm/internlm2-7b-reward",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/internlm__internlm2-7b-reward_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.145726",
      "llm_used": false
    },
    "moonshotai/Moonlight-16B-A3B-Instruct": {
      "model_id": "moonshotai/Moonlight-16B-A3B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/moonshotai__Moonlight-16B-A3B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.148457",
      "llm_used": false
    },
    "aisingapore/SEA-LION-v1-7B-IT": {
      "model_id": "aisingapore/SEA-LION-v1-7B-IT",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/aisingapore__SEA-LION-v1-7B-IT_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.155349",
      "llm_used": false
    },
    "trillionlabs/Trillion-7B-preview": {
      "model_id": "trillionlabs/Trillion-7B-preview",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/trillionlabs__Trillion-7B-preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.158904",
      "llm_used": false
    },
    "inclusionAI/Ling-mini-2.0": {
      "model_id": "inclusionAI/Ling-mini-2.0",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--inclusionAI--Ling-mini-2.0/snapshots/ae2925e082ef9e311fbbb01f2720006611bbdb69` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ling-mini-2.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.162046",
      "llm_used": false
    },
    "ilsp/Meltemi-7B-Instruct-v1": {
      "model_id": "ilsp/Meltemi-7B-Instruct-v1",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ilsp__Meltemi-7B-Instruct-v1_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.170988",
      "llm_used": false
    },
    "ilsp/Meltemi-7B-Instruct-v1.5": {
      "model_id": "ilsp/Meltemi-7B-Instruct-v1.5",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ilsp__Meltemi-7B-Instruct-v1.5_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.179049",
      "llm_used": false
    },
    "tencent/Hunyuan-MT-Chimera-7B-fp8": {
      "model_id": "tencent/Hunyuan-MT-Chimera-7B-fp8",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tencent__Hunyuan-MT-Chimera-7B-fp8_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.185043",
      "llm_used": false
    },
    "allenai/Llama-3.1-Tulu-3-8B-RM": {
      "model_id": "allenai/Llama-3.1-Tulu-3-8B-RM",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/allenai__Llama-3.1-Tulu-3-8B-RM_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.188430",
      "llm_used": false
    },
    "Skywork/Skywork-Reward-V2-Llama-3.1-8B": {
      "model_id": "Skywork/Skywork-Reward-V2-Llama-3.1-8B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Skywork__Skywork-Reward-V2-Llama-3.1-8B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.194372",
      "llm_used": false
    },
    "tencent/Hunyuan-7B-Instruct": {
      "model_id": "tencent/Hunyuan-7B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tencent__Hunyuan-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.201749",
      "llm_used": false
    },
    "Skywork/Skywork-Reward-V2-Llama-3.1-8B-40M": {
      "model_id": "Skywork/Skywork-Reward-V2-Llama-3.1-8B-40M",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Skywork__Skywork-Reward-V2-Llama-3.1-8B-40M_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.207811",
      "llm_used": false
    },
    "inclusionAI/Ring-mini-2.0": {
      "model_id": "inclusionAI/Ring-mini-2.0",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Connection error.",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ring-mini-2.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.210465",
      "llm_used": false
    },
    "tencent/Hunyuan-MT-7B-fp8": {
      "model_id": "tencent/Hunyuan-MT-7B-fp8",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tencent__Hunyuan-MT-7B-fp8_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.217116",
      "llm_used": false
    },
    "trillionlabs/Tri-7B": {
      "model_id": "trillionlabs/Tri-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/trillionlabs__Tri-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.228173",
      "llm_used": false
    },
    "HoangHa/Pensez-v0.1-e5": {
      "model_id": "HoangHa/Pensez-v0.1-e5",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/HoangHa__Pensez-v0.1-e5_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.235650",
      "llm_used": false
    },
    "Skywork/Skywork-Reward-V2-Qwen3-8B": {
      "model_id": "Skywork/Skywork-Reward-V2-Qwen3-8B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Skywork__Skywork-Reward-V2-Qwen3-8B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.242248",
      "llm_used": false
    },
    "AI-MO/Kimina-Prover-Preview-Distill-7B": {
      "model_id": "AI-MO/Kimina-Prover-Preview-Distill-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/AI-MO__Kimina-Prover-Preview-Distill-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.249615",
      "llm_used": false
    },
    "openbmb/MiniCPM3-4B": {
      "model_id": "openbmb/MiniCPM3-4B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/qbw/models--openbmb--MiniCPM3-4B/snapshots/d6b14ddaefdb11c624dd75c3c779549bc90b08cb` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/openbmb__MiniCPM3-4B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.252838",
      "llm_used": false
    },
    "ByteDance-Seed/BFS-Prover-V1-7B": {
      "model_id": "ByteDance-Seed/BFS-Prover-V1-7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--ByteDance-Seed--BFS-Prover-V1-7B/snapshots/750e39030cf25f4af4fcdc81d358123659656cbe` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/ByteDance-Seed__BFS-Prover-V1-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.255839",
      "llm_used": false
    },
    "Dream-org/Dream-Coder-v0-Instruct-7B": {
      "model_id": "Dream-org/Dream-Coder-v0-Instruct-7B",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Dream-org__Dream-Coder-v0-Instruct-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.281200",
      "llm_used": false
    },
    "Dream-org/Dream-v0-Base-7B": {
      "model_id": "Dream-org/Dream-v0-Base-7B",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Dream-org__Dream-v0-Base-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.306383",
      "llm_used": false
    },
    "tiiuae/Falcon-H1-7B-Instruct": {
      "model_id": "tiiuae/Falcon-H1-7B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/tiiuae__Falcon-H1-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.315928",
      "llm_used": false
    },
    "Dream-org/Dream-v0-Instruct-7B": {
      "model_id": "Dream-org/Dream-v0-Instruct-7B",
      "status": "vllm_crash",
      "category": "oom_needs_more_gpu_mem",
      "fixability": "easy_fix",
      "root_cause": "Out of memory error",
      "suggested_fix": "Increase tensor_parallel_size or use GPUs with more memory",
      "error_snippet": "oom",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Dream-org__Dream-v0-Instruct-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.341489",
      "llm_used": false
    },
    "inclusionAI/Ring-mini-linear-2.0": {
      "model_id": "inclusionAI/Ring-mini-linear-2.0",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ring-mini-linear-2.0_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.344292",
      "llm_used": false
    },
    "Dream-org/DreamOn-v0-7B": {
      "model_id": "Dream-org/DreamOn-v0-7B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Dream-org__DreamOn-v0-7B_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.347132",
      "llm_used": false
    },
    "arcee-ai/Arcee-Maestro-7B-Preview": {
      "model_id": "arcee-ai/Arcee-Maestro-7B-Preview",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/arcee-ai__Arcee-Maestro-7B-Preview_stderr.log",
      "analyzed_at": "2026-01-21T17:21:11.353875",
      "llm_used": false
    },
    "MiniMaxAI/SynLogic-7B": {
      "model_id": "MiniMaxAI/SynLogic-7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--MiniMaxAI--SynLogic-7B/snapshots/bfcdfe2571549f8c40f1169cd62221abed5a5cbe` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/MiniMaxAI__SynLogic-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:14.958912",
      "llm_used": false
    },
    "IIC/RigoChat-7b-v2": {
      "model_id": "IIC/RigoChat-7b-v2",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--IIC--RigoChat-7b-v2/snapshots/666a48562f47b0cc09aca23f1ae8df3d0b3ac25c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/IIC__RigoChat-7b-v2_stderr.log",
      "analyzed_at": "2026-01-21T21:13:14.971333",
      "llm_used": false
    },
    "inclusionAI/Ling-lite": {
      "model_id": "inclusionAI/Ling-lite",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--inclusionAI--Ling-lite/snapshots/d80333a0f637caa11a37629af46e0c0cf387de45` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ling-lite_stderr.log",
      "analyzed_at": "2026-01-21T21:13:14.974806",
      "llm_used": false
    },
    "inclusionAI/Ling-lite-1.5": {
      "model_id": "inclusionAI/Ling-lite-1.5",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--inclusionAI--Ling-lite-1.5/snapshots/6b7572bd41f199f34ff6774adfb778619974d34c` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ling-lite-1.5_stderr.log",
      "analyzed_at": "2026-01-21T21:13:14.977855",
      "llm_used": false
    },
    "Kortix/FastApply-7B-v1.0": {
      "model_id": "Kortix/FastApply-7B-v1.0",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Kortix__FastApply-7B-v1.0_stderr.log",
      "analyzed_at": "2026-01-21T21:13:14.989954",
      "llm_used": false
    },
    "FreedomIntelligence/HuatuoGPT-o1-7B": {
      "model_id": "FreedomIntelligence/HuatuoGPT-o1-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/FreedomIntelligence__HuatuoGPT-o1-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.001643",
      "llm_used": false
    },
    "PhysicsWallahAI/Aryabhata-1.0": {
      "model_id": "PhysicsWallahAI/Aryabhata-1.0",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--PhysicsWallahAI--Aryabhata-1.0/snapshots/ffa583f164813296f774a44bf765e8ed51b63f22` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/PhysicsWallahAI__Aryabhata-1.0_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.010524",
      "llm_used": false
    },
    "Qwen/Qwen2.5-7B-Instruct-1M": {
      "model_id": "Qwen/Qwen2.5-7B-Instruct-1M",
      "status": "vllm_crash",
      "category": "cuda_error",
      "fixability": "needs_review",
      "root_cause": "FlashAttention compatibility issue",
      "suggested_fix": "Check GPU architecture compatibility with FlashAttention",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=801344)\u001b[0;0m TypeError: FlashAttention",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen2.5-7B-Instruct-1M_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.025043",
      "llm_used": false
    },
    "SakanaAI/RLT-7B": {
      "model_id": "SakanaAI/RLT-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/SakanaAI__RLT-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.037080",
      "llm_used": false
    },
    "Qwen/Qwen2.5-Coder-7B-Instruct": {
      "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen2.5-Coder-7B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.048231",
      "llm_used": false
    },
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-7B/snapshots/916b56a44061fd5cd7d6a8fb632557ed4f724f60` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/deepseek-ai__DeepSeek-R1-Distill-Qwen-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.066122",
      "llm_used": false
    },
    "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2": {
      "model_id": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/huihui-ai__Qwen2.5-7B-Instruct-abliterated-v2_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.077535",
      "llm_used": false
    },
    "huihui-ai/DeepSeek-R1-Distill-Qwen-7B-abliterated-v2": {
      "model_id": "huihui-ai/DeepSeek-R1-Distill-Qwen-7B-abliterated-v2",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/huihui-ai__DeepSeek-R1-Distill-Qwen-7B-abliterated-v2_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.088878",
      "llm_used": false
    },
    "nvidia/AceInstruct-7B": {
      "model_id": "nvidia/AceInstruct-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/nvidia__AceInstruct-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.095946",
      "llm_used": false
    },
    "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Qwen-7B-v1.1": {
      "model_id": "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Qwen-7B-v1.1",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation framework error",
      "suggested_fix": "Check evalscope configuration",
      "error_snippet": "  File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/evalscope/evaluator/evaluator.py\", line 195, in on_error",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mobiuslabsgmbh__DeepSeek-R1-ReDistill-Qwen-7B-v1.1_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.102861",
      "llm_used": false
    },
    "inclusionAI/Ling-lite-1.5-2507": {
      "model_id": "inclusionAI/Ling-lite-1.5-2507",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--inclusionAI--Ling-lite-1.5-2507/snapshots/6656efdc763a77102207fc66b176e4c5d07a316b` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ling-lite-1.5-2507_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.106158",
      "llm_used": false
    },
    "Qwen/Qwen2.5-Math-7B-PRM800K": {
      "model_id": "Qwen/Qwen2.5-Math-7B-PRM800K",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen2.5-Math-7B-PRM800K_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.109055",
      "llm_used": false
    },
    "Qwen/Qwen2.5-Math-PRM-7B": {
      "model_id": "Qwen/Qwen2.5-Math-PRM-7B",
      "status": "test_error",
      "category": "eval_error",
      "fixability": "needs_review",
      "root_cause": "Evaluation test failed",
      "suggested_fix": "Check test logs for details",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: 'NoneType' object is not iterable",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/Qwen__Qwen2.5-Math-PRM-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.116224",
      "llm_used": false
    },
    "internlm/internlm2_5-7b-chat": {
      "model_id": "internlm/internlm2_5-7b-chat",
      "status": "test_error",
      "category": "api_error",
      "fixability": "needs_review",
      "root_cause": "vLLM 404 error - model loaded but API can't find it (possible vLLM bug or race condition)",
      "suggested_fix": "Retry the model; may be a transient issue with vLLM v1 engine",
      "error_snippet": "Quick sanity test failed: Quick sanity test FAILED: Error code: 404 - {'error': {'message': 'The model `/mnt/baai_cp_perf/hf_models/models--internlm--internlm2_5-7b-chat/snapshots/eb72b541689b0432dade0435feb339b89fdd39ff` does not exist",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/internlm__internlm2_5-7b-chat_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.120671",
      "llm_used": false
    },
    "apple/FastVLM-7B": {
      "model_id": "apple/FastVLM-7B",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/apple__FastVLM-7B_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.123874",
      "llm_used": false
    },
    "inclusionAI/Ring-lite-linear-preview": {
      "model_id": "inclusionAI/Ring-lite-linear-preview",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/inclusionAI__Ring-lite-linear-preview_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.128127",
      "llm_used": false
    },
    "mlx-community/Qwen3-30B-A3B-4bit-DWQ": {
      "model_id": "mlx-community/Qwen3-30B-A3B-4bit-DWQ",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mlx-community__Qwen3-30B-A3B-4bit-DWQ_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.130975",
      "llm_used": false
    },
    "unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit": {
      "model_id": "unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__DeepSeek-R1-Distill-Qwen-32B-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.133927",
      "llm_used": false
    },
    "unsloth/Qwen2.5-7B-Instruct-bnb-4bit": {
      "model_id": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
      "status": "vllm_crash",
      "category": "unsupported_quantization",
      "fixability": "not_fixable",
      "root_cause": "Quantization format not supported",
      "suggested_fix": "Use a different quantization or non-quantized version",
      "error_snippet": "\u001b[0;36m(EngineCore_DP0 pid=1214424)\u001b[0;0m   File \"/mnt/baai_cp_perf/qbw/conda/envs/dschat/lib/python3.11/site-packages/vllm/model_executor/layers/quantization/bitsandbytes",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/unsloth__Qwen2.5-7B-Instruct-bnb-4bit_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.141345",
      "llm_used": false
    },
    "GSAI-ML/LLaDA-1.5": {
      "model_id": "GSAI-ML/LLaDA-1.5",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/GSAI-ML__LLaDA-1.5_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.144432",
      "llm_used": false
    },
    "GSAI-ML/LLaDA-8B-Base": {
      "model_id": "GSAI-ML/LLaDA-8B-Base",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/GSAI-ML__LLaDA-8B-Base_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.147541",
      "llm_used": false
    },
    "GSAI-ML/LLaDA-8B-Instruct": {
      "model_id": "GSAI-ML/LLaDA-8B-Instruct",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/GSAI-ML__LLaDA-8B-Instruct_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.150401",
      "llm_used": false
    },
    "mlx-community/QwQ-32B-4bit": {
      "model_id": "mlx-community/QwQ-32B-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/mlx-community__QwQ-32B-4bit_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.153347",
      "llm_used": false
    },
    "cpatonn/GLM-4.5-Air-AWQ-4bit": {
      "model_id": "cpatonn/GLM-4.5-Air-AWQ-4bit",
      "status": "vllm_crash",
      "category": "unknown",
      "fixability": "needs_review",
      "root_cause": "Could not determine root cause from available logs",
      "suggested_fix": null,
      "error_snippet": "vLLM process crashed with exit code: 1",
      "stderr_file": "/mnt/baai_cp_perf/qbw/evalscope-experiment-runner/experiment_results/vllm_logs/cpatonn__GLM-4.5-Air-AWQ-4bit_stderr.log",
      "analyzed_at": "2026-01-21T21:13:15.156235",
      "llm_used": false
    }
  }
}